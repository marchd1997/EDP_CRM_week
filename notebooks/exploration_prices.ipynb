{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import cvxpy as cp\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import EfficientCVaR\n",
    "from pypfopt.plotting import plot_efficient_frontier\n"
   ],
   "id": "43c58093306c020b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def variance(w, cov):\n",
    "    return np.dot(w.T, np.dot(cov,w)) / (w.shape[0]-1)\n",
    "\n",
    "def returns(w, exp):\n",
    "    return np.dot(w.T, exp) / (w.shape[0]-1)"
   ],
   "id": "2ce41946027b28d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Process Data",
   "id": "e9afcd1ef827a9e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "DATA_PATH = '../data'\n",
    "PRICES_PATH = os.path.join(DATA_PATH, 'prices')\n",
    "SIMULATION_DATA_PATH = os.path.join(DATA_PATH, 'simulation data')\n",
    "prices = pd.read_csv(os.path.join(PRICES_PATH, 'Spain_prices.csv'))"
   ],
   "id": "cbd9e5cae003a7ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prices['price'] = prices['Price (EUR/MWhe)']\n",
    "prices['time'] = pd.to_datetime(prices['Datetime (UTC)'])\n",
    "prices.head()"
   ],
   "id": "95f17c8dfe13124b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df_list = []\n",
    "for file_name in os.listdir(SIMULATION_DATA_PATH):\n",
    "    df = pd.read_csv(os.path.join(SIMULATION_DATA_PATH, file_name),sep = ',', comment = '#')\n",
    "    file_name_split = file_name.split('_')\n",
    "    df['lat_lon'] = file_name_split[2]+ '_' + file_name_split[3]\n",
    "    df_list.append(df)\n",
    "production = pd.concat(df_list)"
   ],
   "id": "3730d604d989fe4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "production['time'] = pd.to_datetime(production['time'])\n",
    "production.head()"
   ],
   "id": "1ff4e5f2ff704b1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "production['hour'] = production['time'].dt.hour\n",
    "production['day'] = production['time'].dt.day\n",
    "production['month'] = production['time'].dt.month\n",
    "production['year'] = production['time'].dt.year\n",
    "\n",
    "prices['hour'] = prices['time'].dt.hour\n",
    "prices['day'] = prices['time'].dt.day\n",
    "prices['month'] = prices['time'].dt.month\n",
    "prices['year'] = prices['time'].dt.year"
   ],
   "id": "7bfffebb1205f9ff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Filter desired dates\n",
    "final_time_price = prices['time'].max()\n",
    "start_time_price = final_time_price - pd.Timedelta(days=365)\n",
    "\n",
    "mask_dates = (prices['time'] <= final_time_price) & (prices['time'] > start_time_price)\n",
    "last_y_prices = prices[mask_dates]\n",
    "last_y_prices.head()"
   ],
   "id": "2a0c21a15f664998"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "production.head()",
   "id": "c74c921a060d61f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Merge in same day but different year and compute revenue\n",
    "df_revenue = pd.merge(production, last_y_prices, on=['hour','day','month'], how='inner')\n",
    "df_revenue = df_revenue[['lat_lon','price','electricity','hour','day','month']]\n",
    "df_revenue['revenue'] = df_revenue['price'] * df_revenue['electricity'] / 1000 # (price is in EUR/MWh and electricity is in kWh)"
   ],
   "id": "13ae81fb9092cc1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Add fictitious year and time stamp so we have a time series\n",
    "df_revenue['year'] = 2019\n",
    "df_revenue['time_stamp'] = df_revenue[['year', 'month', 'day', 'hour']].apply(lambda s : datetime.datetime(*s),axis = 1)"
   ],
   "id": "717d3ba6edb0f8b9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Start model",
   "id": "3745ee628a83a475"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "monthly_rev = pd.pivot_table(df_revenue, values='revenue', index='time_stamp', columns='lat_lon', aggfunc='sum')\n",
    "monthly_rev"
   ],
   "id": "a1e815076a561a28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cov = monthly_rev.cov()\n",
    "exp = monthly_rev.mean()   # mean() Â¿\n",
    "#monthly_rev.sum()\n",
    "# Hourly correlation is still very big although some points close to 0.5\n",
    "monthly_rev.corr()"
   ],
   "id": "13896548d8a736e3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Generate uniform random weights and plot\n",
    "n_samples = 1000\n",
    "n_locations = monthly_rev.shape[1]\n",
    "\n",
    "w_np = np.random.uniform(size=(n_samples, n_locations))\n",
    "w_np /= w_np.sum(axis=1, keepdims=True)\n",
    "df_w = pd.DataFrame(w_np, columns=monthly_rev.columns)\n",
    "\n",
    "df_plot = pd.DataFrame(data = [], index=df_w.index)\n",
    "df_plot['cov'] =  df_w.apply(variance, axis=1, cov=cov)\n",
    "df_plot['exp'] = df_w.apply(returns, axis=1, exp=exp)\n",
    "\n",
    "plt.scatter(x=df_plot['cov'], y=df_plot['exp'])\n",
    "plt.show()"
   ],
   "id": "a5f93c6569d2a9ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute 3 special points (min var, max sharpe, max returns)\n",
    "\n",
    "ef = EfficientFrontier(exp, cov, weight_bounds=(0,1))\n",
    "min_volatility_w = pd.Series((ef.min_volatility())) # ef.clean_weights()\n",
    "\n",
    "ef = EfficientFrontier(exp, cov, weight_bounds=(0,1))\n",
    "max_sharpe_w = pd.Series((ef.max_sharpe()))\n",
    "\n",
    "max_returns_location = monthly_rev.sum().idxmax()\n",
    "max_returns_w = {location: float(0) for location in max_sharpe_w.index}\n",
    "max_returns_w[max_returns_location] = 1.0\n",
    "max_returns_w = pd.Series(max_returns_w)\n",
    "\n",
    "extremes_w = [min_volatility_w, max_sharpe_w, max_returns_w]\n",
    "extremes_var = [variance(w, cov) for w in extremes_w]\n",
    "extremes_exp = [returns(w, exp) for w in extremes_w]"
   ],
   "id": "d41fadffd15a4727"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Compute points in boundary\n",
    "\n",
    "boundary_range_exp = np.linspace(min(extremes_exp)+0.001, max(extremes_exp)-0.001, 100)\n",
    "boundary_w = []\n",
    "\n",
    "for boundary_exp in boundary_range_exp:\n",
    "    ef = EfficientFrontier(exp, cov, weight_bounds=(0,1))\n",
    "    w = pd.Series(ef.efficient_return(boundary_exp))\n",
    "    boundary_w.append(w)\n",
    "\n",
    "boundary_var = [variance(w, cov) for w in boundary_w]\n",
    "boundary_exp = [returns(w, exp) for w in boundary_w]"
   ],
   "id": "39d5580774d79a06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Now we get more resonable picture TODO: see which linear convinations we get the blue curve.\n",
    "ef = EfficientFrontier(exp, cov,  weight_bounds=(0,1))\n",
    "fig, ax = plt.subplots()\n",
    "plot_efficient_frontier(ef, ax=ax, show_assets=True)\n",
    "plt.scatter(x=np.sqrt(df_plot['cov']), y=df_plot['exp'])\n",
    "plt.scatter(np.sqrt(extremes_var), extremes_exp)\n",
    "plt.show()"
   ],
   "id": "d6323926edf5123d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO:\n",
    "# - Get 3 special points\n",
    "# - Get curve\n",
    "# - Plot solutions on map nicely.\n",
    "# -\n",
    "# - compare minimum vairiance/sharpe with what one would get in specific location. How much improvement\n",
    "# - Look correlations and see if we can get good result with fewer assets than boundary?\n",
    "#\n",
    "#  utilitzar els 10 anys de preus? Fer model treient dades de vent reals i produccio?"
   ],
   "id": "82d3ed8bed092bb2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "#TODO: mirar si algunes estacions mai utilitzades en corva.",
   "id": "c08a1b10a25dce61"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "15fb77098bf19028"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
